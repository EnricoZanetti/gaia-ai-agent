{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c81ca61",
   "metadata": {},
   "source": [
    "### **Load the metadata.jsonl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d08b1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task_id': '8f80e01c-1296-4371-9486-bb3d68651a60',\n",
       "  'Question': 'Using bass clef notes, what is the age of someone who has experienced the word spelled out in the sheet music by the note letters the total number of lines and notes minus the number of notes on lines in the image?',\n",
       "  'Level': 2,\n",
       "  'Final answer': '90',\n",
       "  'file_name': '8f80e01c-1296-4371-9486-bb3d68651a60.png',\n",
       "  'Annotator Metadata': {'Steps': '1. Open the file.\\n2. Translate the letters to bass notes (\"D E C A D E\").\\n3. Count the lines (5).\\n4. Count the notes (6).\\n5. Count the notes on lines (2).\\n6. Add the lines and notes (11).\\n7. Subtract the notes on lines (11 - 2).\\n8. Multiply 10 by 9 (90).\\n9. Note the age given.',\n",
       "   'Number of steps': '9',\n",
       "   'How long did this take?': '5 minutes',\n",
       "   'Tools': '1. Image recognition\\n2. Bass note data\\n3. Calculator',\n",
       "   'Number of tools': '3'}},\n",
       " {'task_id': '6b078778-0b90-464d-83f6-59511c811b01',\n",
       "  'Question': \"The Metropolitan Museum of Art has a portrait in its collection with an accession number of 29.100.5. Of the consecrators and co-consecrators of this portrait's subject as a bishop, what is the name of the one who never became pope?\",\n",
       "  'Level': 2,\n",
       "  'Final answer': 'Alfonso Visconti',\n",
       "  'file_name': '',\n",
       "  'Annotator Metadata': {'Steps': '1. I searched for \"Metropolitan Museum of Art search collection\" using a search engine to get to the \"Search the Collection\" page on the Metropolitan Museum of Art\\'s website.\\n2. I selected \"Accession Number\" in the search field dropdown and entered \"29.100.5\" into the text input, noting that the only result is a portrait titled \"Cardinal Fernando Niño de Guevara (1541–1609)\"\\n3. I went to Fernando Niño de Guevara\\'s Wikipedia page and noted that he was consecrated bishop by Pope Clement VIII with Camillo Borghese and Alfonso Visconti as co-consecrators.\\n4. I eliminated Pope Clement VIII as the answer since he was obviously a pope based on his title.\\n5. I went to Camillo Borghese\\'s Wikipedia page and noted that he became Pope Paul V, eliminating him as the answer.\\n6. I went to Alfonso Visconti\\'s Wikipedia page and noted that he never became pope, so the answer to the question is \"Alfonso Visconti\".',\n",
       "   'Number of steps': '6',\n",
       "   'How long did this take?': '5 minutes',\n",
       "   'Tools': '1. Web browser\\n2. Search engine',\n",
       "   'Number of tools': '2'}},\n",
       " {'task_id': '3627a8be-a77f-41bb-b807-7e1bd4c0ebdf',\n",
       "  'Question': \"The object in the British Museum's collection with a museum number of 2012,5015.17 is the shell of a particular mollusk species. According to the abstract of a research article published in Science Advances in 2021, beads made from the shells of this species were found that are at least how many thousands of years old?\",\n",
       "  'Level': 2,\n",
       "  'Final answer': '142',\n",
       "  'file_name': '',\n",
       "  'Annotator Metadata': {'Steps': '1. Use search engine to search for \"British Museum search collection\" and navigate to the British Museum\\'s collection search webpage.\\n2. Select \"Museum number\" as search field and \"2012,5015.17\" in text box, then run search.\\n3. Open the page for the single result and note that the description says that this is the shell of an individual of the Nassa gibbosula species.\\n4. Use search engine to search for \"Nassa gibbosula\".\\n5. Note that according to the search result from the World Register of Marine Species website, Nassa gibbosula is not an accepted species name.\\n6. Open the page for Nassa gibbosula on the World Register of Marine Species website.\\n7. Scan the page and note that the accepted species name is Tritia gibbosula.\\n8. Use search engine to search for \"Science Advances 2021 Tritia gibbosula\".\\n9. Find that the top result is an article from 2021 in Science Advances titled \"Early Middle Stone Age personal ornaments from Bizmoune Cave, Essaouira, Morocco\".\\n10. Scan abstract and note that the article discusses beads made from Tritia gibbosula shells that date to at least 142 thousand years ago, giving a final answer of 142.',\n",
       "   'Number of steps': '10',\n",
       "   'How long did this take?': '12 minutes',\n",
       "   'Tools': '1. Web browser\\n2. Search engine',\n",
       "   'Number of tools': '2'}}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "qa = [\n",
    "    json.loads(line) for line in pathlib.Path(\"metadata.jsonl\").read_text().splitlines()\n",
    "]\n",
    "few_shots = random.sample(qa, 3)\n",
    "\n",
    "few_shots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0faa7",
   "metadata": {},
   "source": [
    "### **Define the Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6259802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/rs_tn3ms65s6c58s51w6850w0000gn/T/ipykernel_44026/265665062.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
      "/Users/enricozanetti/miniconda3/envs/AI_AGENT_PY311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=f\"Q: {q['Question']}\\nA: {q['Final answer']}\",\n",
    "        metadata={\"id\": q[\"task_id\"]},\n",
    "    )\n",
    "    for q in qa\n",
    "]\n",
    "\n",
    "vstore = FAISS.from_documents(docs, embed)\n",
    "retriever = vstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a2a206",
   "metadata": {},
   "source": [
    "### **Define the tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e2ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "similar_q_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"similar_questions\",\n",
    "    description=\"Return similar solved GAIA level-1 Q&A pairs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0c150",
   "metadata": {},
   "source": [
    "### **Craft the system prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3bfcadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt: \n",
      "You are a general AI assistant. I will ask you a question. Report your thoughts, and finish your answer with the following template: FINAL ANSWER: [YOUR FINAL ANSWER].\n",
      "YOUR FINAL ANSWER should be a number OR as few words as possible OR a comma separated list of numbers and/or strings.\n",
      "If you are asked for a number, don't use comma to write your number neither use units such as $ or percent sign unless specified otherwise.\n",
      "If you are asked for a string, don't use articles, neither abbreviations (e.g. for cities), and write the digits in plain text unless specified otherwise.\n",
      "If you are asked for a comma separated list, apply the above rules depending of whether the element to be put in the list is a number or a string.\n",
      "\n",
      "Q: Using bass clef notes, what is the age of someone who has experienced the word spelled out in the sheet music by the note letters the total number of lines and notes minus the number of notes on lines in the image?\n",
      "A: 90\n",
      "Q: The Metropolitan Museum of Art has a portrait in its collection with an accession number of 29.100.5. Of the consecrators and co-consecrators of this portrait's subject as a bishop, what is the name of the one who never became pope?\n",
      "A: Alfonso Visconti\n",
      "Q: The object in the British Museum's collection with a museum number of 2012,5015.17 is the shell of a particular mollusk species. According to the abstract of a research article published in Science Advances in 2021, beads made from the shells of this species were found that are at least how many thousands of years old?\n",
      "A: 142\n"
     ]
    }
   ],
   "source": [
    "from constants import SYSTEM_PROMPT\n",
    "\n",
    "for ex in few_shots:\n",
    "    SYSTEM_PROMPT += f\"\\nQ: {ex['Question']}\\nA: {ex['Final answer']}\"\n",
    "\n",
    "print(f\"System Prompt: {SYSTEM_PROMPT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f4bfc",
   "metadata": {},
   "source": [
    "### **Choose an LLM Backend**\n",
    "\n",
    "- Quick & free: gemini-1.5-flash (as in notebook)\n",
    "\n",
    "- Familiar: gpt-4o via OpenAI\n",
    "\n",
    "- Local: mistral-7b-instruct with ollama for zero cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ac4068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/rs_tn3ms65s6c58s51w6850w0000gn/T/ipykernel_44026/1499005951.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5557b8",
   "metadata": {},
   "source": [
    "### **Wire it all together with Langgraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c83a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm.invoke([SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([similar_q_tool]))  # add web tools later\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "agent_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db228d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(question: str) -> str:\n",
    "    out = agent_graph.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "    return out[\"messages\"][-1].content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d2eca",
   "metadata": {},
   "source": [
    "### **Hook up the GAIA evaluation API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc441d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "\n",
    "API = \"https://GAIA_API_URL\"  # replace\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    qs = requests.get(f\"{API}/questions\").json()\n",
    "    answers = [\n",
    "        {\"task_id\": q[\"id\"], \"submitted_answer\": solve(q[\"question\"])} for q in qs\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "        \"username\": \"enricozan\",\n",
    "        \"agent_code\": \"https://huggingface.co/spaces/enricozan/gaia-ai-agent/tree/main\",\n",
    "        \"answers\": answers,\n",
    "    }\n",
    "    r = requests.post(f\"{API}/submit\", json=payload)\n",
    "    print(\"Leaderboard response:\", r.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd579701",
   "metadata": {},
   "source": [
    "### **Wrap it in Gradio for your Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c65d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    q = gr.Textbox(label=\"GAIA question\")\n",
    "    a = gr.Textbox(label=\"Answer\")\n",
    "    btn = gr.Button(\"Solve\")\n",
    "    btn.click(lambda x: solve(x), inputs=q, outputs=a)\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_AGENT_PY311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
